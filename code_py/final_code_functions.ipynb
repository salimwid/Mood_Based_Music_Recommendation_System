{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d328ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to use\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from fer import Video, FER\n",
    "from moviepy.editor import *\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b1134f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func1: submit video\n",
    "\n",
    "def submit_video():\n",
    "    \n",
    "    root = Tk()\n",
    "    root.withdraw()\n",
    "\n",
    "    root.attributes('-topmost', True)\n",
    "    open_file = filedialog.askopenfilenames()\n",
    "    clip= VideoFileClip(open_file[0]).subclip(0,10)\n",
    "    clip.write_videofile('movie.mp4')\n",
    "    clip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8d5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func2: load and process video\n",
    "\n",
    "def load_and_process():\n",
    "    face_detector = FER(mtcnn=True)\n",
    "    input_video = Video('movie.mp4')\n",
    "    processing_data = input_video.analyze(face_detector, display=False)\n",
    "    \n",
    "    vid_df = input_video.to_pandas(processing_data)\n",
    "    vid_df = input_video.get_first_face(vid_df)\n",
    "    vid_df = input_video.get_emotions(vid_df)\n",
    "    return vid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df29a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/250 [00:00<?, ?frames/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-12-2021:21:10:00,394 INFO     [classes.py:199] 25.00 fps, 250 frames, 10.00 seconds\n",
      "15-12-2021:21:10:00,408 INFO     [classes.py:207] Making directories at output\n",
      "15-12-2021:21:10:00,415 INFO     [classes.py:352] Deleted pre-existing output/movie_output.mp4\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffda70c70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ffdc663b8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [07:32<00:00,  1.81s/frames]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15-12-2021:21:17:33,258 INFO     [classes.py:320] Completed analysis: saved to output/movie_output.mp4\n",
      "15-12-2021:21:17:33,259 INFO     [classes.py:327] Starting to Zip\n",
      "15-12-2021:21:17:33,377 INFO     [classes.py:338] Compressing: 20%\n",
      "15-12-2021:21:17:33,454 INFO     [classes.py:338] Compressing: 40%\n",
      "15-12-2021:21:17:33,540 INFO     [classes.py:338] Compressing: 60%\n",
      "15-12-2021:21:17:33,610 INFO     [classes.py:338] Compressing: 80%\n",
      "15-12-2021:21:17:33,694 INFO     [classes.py:338] Compressing: 100%\n",
      "15-12-2021:21:17:33,703 INFO     [classes.py:339] Zip has finished\n"
     ]
    }
   ],
   "source": [
    "vid_df = load_and_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac887d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func3: def top emo/ 2 emo || same and opposite feeling depending on desired use case\n",
    "\n",
    "def top_emo(vid_df): # to improve, add flex to define num of emotions vs hard coding\n",
    "    # compute weights \n",
    "    emo_matrix=pd.DataFrame(vid_df.sum(axis=0))\n",
    "    emo_matrix.columns=['emo_score']\n",
    "    emo_matrix['weight']=100*emo_matrix['emo_score']/np.sum(emo_matrix['emo_score'])\n",
    "    \n",
    "    # determine top emotion or n emotions\n",
    "    max_emo_label=emo_matrix['weight'].idxmax()\n",
    "    max_emo_value=np.max(emo_matrix['weight'])\n",
    "    emo_threshold=85\n",
    "    \n",
    "    feeling=()\n",
    "\n",
    "    if max_emo_value>=emo_threshold:\n",
    "        feeling=max_emo_label\n",
    "    else:\n",
    "        emo_matrix.sort_values('weight',inplace=True,ascending=False)\n",
    "        emo_matrix=emo_matrix.reset_index()\n",
    "        first = emo_matrix['index'][0].title()\n",
    "        second = emo_matrix['index'][1].title()\n",
    "        feeling = tuple(sorted((first,second)))\n",
    "    \n",
    "    # hard code same and diff feeling songs\n",
    "\n",
    "    spotify_moods = [\"Distressed\", \"Energetic\", \"Excitement\", \"Contentment\",\"Depressed\",\"Misery\"]\n",
    "    video_moods = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\",\"Sad\",\"Surprised\",\"Neutral\"]\n",
    "    dict_of_video_moods_same = {}\n",
    "    dict_of_video_moods_diff = {}\n",
    "\n",
    "    ## same-feeling songs\n",
    "\n",
    "    ### singles\n",
    "    dict_of_video_moods_same[('Angry','Angry')] = ['Distressed',\"Energetic\"]\n",
    "    dict_of_video_moods_same[('Disgust','Disgust')] = ['Distressed']\n",
    "    dict_of_video_moods_same[('Fear','Fear')] = ['Distressed','Misery']\n",
    "    dict_of_video_moods_same[('Happy','Happy')] = ['Excitement']\n",
    "    dict_of_video_moods_same[('Sad','Sad')] = ['Depressed']\n",
    "    dict_of_video_moods_same[('Surprised','Surprised')] = ['Energetic']\n",
    "    dict_of_video_moods_same[('Neutral','Neutral')] = ['Depressed','Excitement']\n",
    "\n",
    "    ### doubles\n",
    "    for i in range(len(video_moods)):\n",
    "        for j in range(i+1,len(video_moods)):\n",
    "            dict_of_video_moods_same[tuple(sorted((video_moods[i],video_moods[j])))] = []\n",
    "\n",
    "    #### angry\n",
    "    dict_of_video_moods_same[('Angry','Disgust')] = ['Misery']\n",
    "    dict_of_video_moods_same[('Angry','Fear')] = ['Distressed','Energetic']\n",
    "    dict_of_video_moods_same[('Angry','Happy')] = ['Energetic']\n",
    "    dict_of_video_moods_same[('Angry','Sad')] = ['Depressed']\n",
    "    dict_of_video_moods_same[('Angry','Surprised')] = ['Distressed']\n",
    "    dict_of_video_moods_same[('Angry','Neutral')] = ['Distressed','Energetic']\n",
    "\n",
    "    #### disgust\n",
    "    dict_of_video_moods_same[('Disgust','Fear')] = ['Distressed']\n",
    "    dict_of_video_moods_same[('Disgust','Happy')] = ['Excitement']\n",
    "    dict_of_video_moods_same[('Disgust','Sad')] = ['Misery']\n",
    "    dict_of_video_moods_same[('Disgust','Surprised')] = ['Energetic']\n",
    "    dict_of_video_moods_same[('Disgust','Neutral')] = ['Distressed']\n",
    "\n",
    "    #### fear\n",
    "    dict_of_video_moods_same[('Fear','Happy')] = ['Energetic']\n",
    "    dict_of_video_moods_same[('Fear','Sad')] = ['Depressed','Misery']\n",
    "    dict_of_video_moods_same[('Fear','Surprised')] = ['Misery']\n",
    "    dict_of_video_moods_same[('Fear','Neutral')] = ['Distressed','Misery']\n",
    "\n",
    "    #### happy\n",
    "    dict_of_video_moods_same[('Happy','Sad')] = ['Contentment','Misery']\n",
    "    dict_of_video_moods_same[('Happy','Surprised')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_same[('Happy','Neutral')] = ['Excitement']\n",
    "\n",
    "    #### sad\n",
    "    dict_of_video_moods_same[('Sad','Surprised')] = ['Distressed']\n",
    "\n",
    "    #### neutral\n",
    "    dict_of_video_moods_same[('Neutral','Sad')] = ['Depressed']\n",
    "    dict_of_video_moods_same[('Neutral','Surprised')] = ['Energetic']\n",
    "\n",
    "    ## opposite-feeling songs\n",
    "\n",
    "    dict_of_video_moods_diff[('Angry','Angry')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Disgust','Disgust')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Fear','Fear')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Happy','Happy')] = ['Excitement']\n",
    "    dict_of_video_moods_diff[('Sad','Sad')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Surprised','Surprised')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Neutral','Neutral')] = ['Excitement','Depressed']  \n",
    "\n",
    "    ### doubles\n",
    "    for i in range(len(video_moods)):\n",
    "        for j in range(i+1,len(video_moods)):\n",
    "            dict_of_video_moods_diff[tuple(sorted((video_moods[i],video_moods[j])))] = []\n",
    "\n",
    "    #### angry\n",
    "    dict_of_video_moods_diff[('Angry','Disgust')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Angry','Fear')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Angry','Happy')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Angry','Sad')] = ['Contentment','Energetic']\n",
    "    dict_of_video_moods_diff[('Angry','Surprised')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Angry','Neutral')] = ['Contentment']\n",
    "\n",
    "    #### disgust\n",
    "    dict_of_video_moods_diff[('Disgust','Fear')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Disgust','Happy')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Disgust','Sad')] = ['Contentment','Energetic']\n",
    "    dict_of_video_moods_diff[('Disgust','Surprised')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Disgust','Neutral')] = ['Contentment']\n",
    "\n",
    "    #### fear\n",
    "    dict_of_video_moods_diff[('Fear','Happy')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Fear','Sad')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Fear','Surprised')] = ['Contentment']\n",
    "    dict_of_video_moods_diff[('Fear','Neutral')] = ['Contentment','Excitement']\n",
    "\n",
    "    #### happy - intentionally the same recommendations to same-feeling\n",
    "    dict_of_video_moods_diff[('Happy','Sad')] = ['Contentment','Misery']\n",
    "    dict_of_video_moods_diff[('Happy','Surprised')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Happy','Neutral')] = ['Excitement']\n",
    "\n",
    "    #### sad\n",
    "    dict_of_video_moods_diff[('Sad','Surprised')] = ['Energetic']\n",
    "\n",
    "    #### neutral\n",
    "    dict_of_video_moods_diff[('Neutral','Sad')] = ['Contentment','Excitement']\n",
    "    dict_of_video_moods_diff[('Neutral','Surprised')] = ['Contentment']\n",
    "    \n",
    "    # return same and opposite feeling lists\n",
    "    \n",
    "    same=dict_of_video_moods_same[feeling]\n",
    "    opposite=dict_of_video_moods_diff[feeling]\n",
    "    \n",
    "    return same, opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad31839",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Include top_emo later\n",
    "#spotify_category('valence_arousal_dataset.csv', top_emo(vid_df)[0], top_emo(vid_df)[1])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d954574",
   "metadata": {},
   "source": [
    "#Not used\n",
    "def mapping_centroids(file):\n",
    "    \n",
    "    spotify = pd.read_csv(file)\n",
    "    spotify_vals = spotify[['valence','energy']].values\n",
    "    \n",
    "    #Number of clusters chosen = 6\n",
    "    kmeans = KMeans(n_clusters = 6)\n",
    "    clusters = kmeans.fit_predict(spotify_vals)\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for center in centers:\n",
    "        x.append(center[0])\n",
    "        y.append(center[1])\n",
    "\n",
    "    mood_centroids = ['depressed','misery','contentment','distressed','excitement','energetic']\n",
    "    centroid_location_dict = {}\n",
    "\n",
    "    i = 0\n",
    "    for mood in mood_centroids:\n",
    "        centroid_location_dict[mood] = [x[i] , y[i]]\n",
    "        i += 1\n",
    "        \n",
    "    return centroid_location_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad4a0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mood_centroids = {'Depressed':[0.19066008, 0.21390282],'Misery':[0.29176613, 0.55255357], 'Contentment': [0.67930098, 0.46349509], 'Distressed':[0.21726171, 0.89302689], 'Excitement':[0.83923924, 0.80557057], 'Energetic':[0.53893319, 0.83543712]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d9040ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_combined_moods(df, mood1, mood2):\n",
    "    data = pd.read_csv(df)\n",
    "    \n",
    "    mean_valence = np.average([mood_centroids[mood1][0], mood_centroids[mood2][0]])\n",
    "    mean_energy = np.average([mood_centroids[mood1][1], mood_centroids[mood2][1]])\n",
    "    \n",
    "    selected_moods = data.loc[data['moods_label'].isin([mood1, mood2])]\n",
    "    selected_moods['euclidian_distance'] = ((selected_moods['valence'] - mean_valence)**2 + (selected_moods['energy'] - mean_energy)**2)**(1/2)\n",
    "    \n",
    "    #Select 1 song from 10 songs that have closest Euclidian Distance\n",
    "    selected_track = selected_moods.sort_values('euclidian_distance').iloc[0:10]['track_name'].sample(n=10)\n",
    "    \n",
    "    return selected_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93be75ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "submit_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bd7d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_emo(vid_df)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ac4d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def button_click(selected_mood):\n",
    "    data = pd.read_csv('valence_arousal_dataset_labeled.csv')\n",
    "    feelings = top_emo(vid_df)\n",
    "    if selected_mood == 'same' and len(feelings[0]) > 1:\n",
    "        return top10_combined_moods('valence_arousal_dataset_labeled.csv', feelings[0][0], feelings[0][1])\n",
    "    elif selected_mood == 'opposite' and len(feelings[1]) > 1:\n",
    "        return top10_combined_moods('valence_arousal_dataset_labeled.csv', feelings[1][0], feelings[1][1])\n",
    "    elif selected_mood == 'same':\n",
    "        return data[data['moods_label'] == feelings[0][0]].sample(n=10)['track_name']\n",
    "    else:\n",
    "        return data[data['moods_label'] == feelings[1][0]].sample(n=10)['track_name']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15ca555b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913      Pot-Pourri: Quando Eu Durmo / Balaio Grande\n",
       "8927                           Fire Bun A Weak Heart\n",
       "6689                             Propuesta Indecente\n",
       "1404                              Fascinating Rhythm\n",
       "11113                                    Taxi Bamako\n",
       "159                                          Mandjou\n",
       "2160                                 Nuh Chatta Ting\n",
       "8934                                   Positive Herb\n",
       "3838                              Das zweite Gesicht\n",
       "6456                              Dinosaur Christmas\n",
       "Name: track_name, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "button_click('opposite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
